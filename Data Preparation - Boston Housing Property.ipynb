{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Assessed Value of Single Family Homes in Boston: Data Preperation\n",
    "### 2019 Property Assessment Dataset\n",
    "\n",
    "#### Janaki E. Viswanathan\n",
    "\n",
    "#### Dataset link: https://data.boston.gov/dataset/property-assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "### To analyze the dataset the SEMMA process will be followed. Sample → Explore → Modify → Model → Assess.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sample\n",
    "### -- Gather data and import data into Pandas dataframe\n",
    "### -- Select all rows with PTYPE =101(Single Family Homes records)\n",
    "### -- Drop all columns/variables not associated with single family homes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Boston Property dataset. Make sure to specified file location.\n",
    "data = pd.read_csv('C:/Users/530992/Python/Project/fy19fullpropassess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if all attributes and records were read.\n",
    "print('Number of records:')\n",
    "print(data.shape[0])\n",
    "print('Number of attributes:')\n",
    "print(data.shape[1])\n",
    "\n",
    "# Print the top 5 records to validate data has been read correctly.\n",
    "print(data.head())\n",
    "print(\"Datatype and variable information\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Single family homes using property type, PTYPE, 101.\n",
    "sfhomes = data[data['PTYPE']== 101]\n",
    "print('Number of records:')\n",
    "print(sfhomes.shape[0])\n",
    "print('Number of attributes:')\n",
    "print(sfhomes.shape[1])\n",
    "print(sfhomes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with all missing values. These columns will need to be dropped.\n",
    "count = 0\n",
    "for i in sfhomes:\n",
    "    if sfhomes[i].count() == 0:\n",
    "        print(i)\n",
    "        count = count +1\n",
    "print (\"There are \",count, \" rows with all missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop 27 rows with all missing values:\n",
    "sfhomes=sfhomes.dropna(axis=1, how='all',  inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows to verify non single family homes were dropped.\n",
    "print('Number of records:')\n",
    "print(sfhomes.shape[0])\n",
    "print('Number of attributes:')\n",
    "print(sfhomes.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns that don't provide valuable information to the model, such as street name.\n",
    "sfhomes.drop(['CM_ID','GIS_ID', 'ST_NAME_SUF','PID','ST_NUM','ST_NAME','OWNER','OWN_OCC','MAIL_ADDRESSEE','MAIL_ADDRESS',\n",
    "              'MAIL CS','MAIL_ZIPCODE'], axis=1, inplace = True)\n",
    "\n",
    "# Verify columns were dropped and records remain the same.\n",
    "print('Number of records:')\n",
    "print(sfhomes.shape[0])\n",
    "print('Number of attributes:')\n",
    "print(sfhomes.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore\n",
    "### -- Looking for data issues & relationships among the attributes\n",
    "####        - Missing Value Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indetify columns with any missing values.\n",
    "for i in sfhomes:\n",
    "    if sfhomes[i].count() < sfhomes.shape[0]:\n",
    "        print(i, \" \",sfhomes.shape[0]- sfhomes[i].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values for LAND_SF\n",
    "print('Count of missing values in LAND_SF')\n",
    "print(np.count_nonzero(sfhomes['LAND_SF'].isnull()))\n",
    "\n",
    "# Calculate the mean of LAND_SF to impute missing values.\n",
    "sfhomes['LAND_SF'].mean()\n",
    "\n",
    "# Impute missing values with mean.\n",
    "sfhomes['LAND_SF'].fillna(sfhomes['LAND_SF'].mean(), inplace=True)\n",
    "\n",
    "# Verify missing values were imputed.\n",
    "print('Count of missing values in LAND_SF after imputing')\n",
    "print(np.count_nonzero(sfhomes['LAND_SF'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify number of missing values and the mode for Structure_Class\n",
    "print('Count of missing values in STRUCTURE_CLASS ')\n",
    "print(np.count_nonzero(sfhomes['STRUCTURE_CLASS'].isnull()))\n",
    "print(\"Mode: \" , sfhomes['STRUCTURE_CLASS'].mode())\n",
    "print()\n",
    "\n",
    "# Convert structure class into category and impute missing value with Mode.\n",
    "sfhomes['STRUCTURE_CLASS']=sfhomes['STRUCTURE_CLASS'].astype('category')\n",
    "sfhomes['STRUCTURE_CLASS'].fillna(sfhomes['STRUCTURE_CLASS'].value_counts().index[0], inplace=True)\n",
    "\n",
    "# Verify all missing values were imputed with the mode.\n",
    "print('Count of missing values in STRUCTURE_CLASS after imputing')\n",
    "print(np.count_nonzero(sfhomes['STRUCTURE_CLASS'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Impute missing values and '0' values in YR_REMOD with values in YR_BUILT Column\n",
    "\n",
    "# Count number of missing values\n",
    "print('Count of missing values in YR_REMOD ')\n",
    "print(np.count_nonzero(sfhomes['YR_REMOD'].isnull()))\n",
    "\n",
    "# Replace missing values with year built values\n",
    "sfhomes['YR_REMOD'].fillna(sfhomes['YR_BUILT'],inplace=True)\n",
    "\n",
    "print('Count of missing values in YR_REMOD after imputing missing values: ')\n",
    "print(np.count_nonzero(sfhomes['YR_REMOD'].isnull()))\n",
    "\n",
    "# Replace year value '0' with YR_BUILT value\n",
    "sfhomes['YR_REMOD'].replace(0,sfhomes['YR_BUILT'], inplace = True)\n",
    "\n",
    "print('Count of missing values in YR_REMOD after imputing missing and zeros: ')\n",
    "print(np.count_nonzero(sfhomes['YR_REMOD'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indetify columns with any missing values.\n",
    "for i in sfhomes:\n",
    "    if sfhomes[i].count() < sfhomes.shape[0]:\n",
    "        print(i, \" \",sfhomes.shape[0]- sfhomes[i].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate R_BTH_STYLE2 missing values and replace them with N/A\n",
    "\n",
    "# Check records to see if Half baths are considered in the style columns\n",
    "sfhomes_baths = sfhomes[sfhomes['R_FULL_BTH']== 1][['R_FULL_BTH','R_HALF_BTH','R_BTH_STYLE2']]\n",
    "print(sfhomes_baths.head())\n",
    "\n",
    "# Calculate total number of baths (full and half)\n",
    "sfhomes['TOTAL_BATHS'] = sfhomes['R_FULL_BTH'] + sfhomes['R_HALF_BTH']\n",
    "\n",
    "sfhomes['R_BTH_STYLE2'] = np.where((sfhomes['TOTAL_BATHS'] <2), 'N/A', sfhomes['R_BTH_STYLE2'])\n",
    "\n",
    "# Check for missing values\n",
    "print()\n",
    "print('Count of missing values in R_BTH_STYLE2')\n",
    "print(np.count_nonzero(sfhomes['R_BTH_STYLE2'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Investigate R_BTH_STYLE3 missing values and replace them with N/A\n",
    "sfhomes['R_BTH_STYLE3'] = np.where((sfhomes['TOTAL_BATHS'] <3), 'N/A', sfhomes['R_BTH_STYLE3'])\n",
    "\n",
    "# Check for missing values\n",
    "print('Count of missing values in R_BTH_STYLE3')\n",
    "print(np.count_nonzero(sfhomes['R_BTH_STYLE3'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate R_KITH_STYLE2 and R_KITH_STYLE3  missing values and replace them with N/A\n",
    "\n",
    "# Make missing values N/A if record doesn't meet criteria specified.\n",
    "sfhomes['R_KITCH_STYLE2'] = np.where((sfhomes['R_KITCH'] <2), 'N/A', sfhomes['R_KITCH_STYLE2'])\n",
    "sfhomes['R_KITCH_STYLE3'] = np.where((sfhomes['R_KITCH'] <3), 'N/A', sfhomes['R_KITCH_STYLE3'])\n",
    "\n",
    "# Check for missing values in R_KITH_STYLE2 and R_KITH_STYLE3\n",
    "print('Count of missing values in R_KITCH_STYLE2')\n",
    "print(np.count_nonzero(sfhomes['R_KITCH_STYLE2'].isnull()))\n",
    "print('Count of missing values in R_KITCH_STYLE3')\n",
    "print(np.count_nonzero(sfhomes['R_KITCH_STYLE3'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check for missing values\n",
    "print(\"Number of Missing Values in columns\")\n",
    "for i in sfhomes:\n",
    "    if sfhomes[i].count() < sfhomes.shape[0]:\n",
    "        print(sfhomes.shape[0]-sfhomes[i].count(), \" \", i )\n",
    "    else:\n",
    "        print('No missing values', \" - \", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Modify\n",
    "### -- Attribute Encoding\n",
    "### -- Transform data/ create new attributes.\n",
    "### -- Partition data into training & assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regular AV_Total\n",
    "AV_TOTAL =plt.figure(figsize=(17,10))\n",
    "sfhomes.hist(column='AV_TOTAL')\n",
    "plt.xlabel(\"Assessed Value\",fontsize=15)\n",
    "plt.ylabel(\"Frequency\",fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "#### 1. logTotal - AV_Total is not normal. It has to be Log transformed.\n",
    "sfhomes[\"logTotal\"] = np.log(sfhomes['AV_TOTAL'])\n",
    "\n",
    "# Plot logged AV_Total\n",
    "logTotal =plt.figure(figsize=(17,10))\n",
    "sfhomes.hist(column='logTotal')\n",
    "plt.xlabel(\"Assessed Value\",fontsize=15)\n",
    "plt.ylabel(\"Frequency\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age - Calculate age of home\n",
    "t1 = datetime.now()\n",
    "sfhomes['Age'] = t1.year - sfhomes['YR_BUILT']\n",
    "\n",
    "#Display values to verify calculation was sucessful\n",
    "print(\"Age calculation for the top 5 records:\")\n",
    "sfhomes['Age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of years since last remodeled.\n",
    "sfhomes['YR_SINCE_REMOD'] = t1.year - sfhomes['YR_REMOD']\n",
    "print(\"Years Since Remodeled calculation for the top 5 records:\")\n",
    "print(sfhomes['YR_SINCE_REMOD'].head())\n",
    "\n",
    "# Verify columns were added to dataframe\n",
    "sfhomes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns Not required for analysis due to leakage variables or duplicate information\n",
    "sfhomes.drop(['PTYPE', 'LU','YR_BUILT','YR_REMOD','TOTAL_BATHS','GROSS_TAX','AV_BLDG','AV_LAND' ],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create excel file with cleaned and useful modeling columns\n",
    "sfhomes.to_csv(\"cleaned_sfhomes.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot to encode categorical variables\n",
    "sfhomes_model = pd.get_dummies(sfhomes, columns=['ZIPCODE','STRUCTURE_CLASS', 'R_BLDG_STYL', 'R_ROOF_TYP',\n",
    "                                                    'R_EXT_FIN','R_BTH_STYLE', 'R_BTH_STYLE2', 'R_BTH_STYLE3', 'R_KITCH', 'R_KITCH_STYLE',\n",
    "                                                    'R_KITCH_STYLE2', 'R_KITCH_STYLE3', 'R_HEAT_TYP', 'R_AC', 'R_FPLACE', \n",
    "                                                    'R_EXT_CND', 'R_OVRALL_CND', 'R_INT_CND', 'R_INT_FIN', \n",
    "                                                    'R_VIEW'], drop_first=False)\n",
    "\n",
    "# Verify columns were created and old variables were dropped.\n",
    "print('Number of records:')\n",
    "print(sfhomes_model.shape[0])\n",
    "print('Number of attributes:')\n",
    "print(sfhomes_model.shape[1])\n",
    "sfhomes_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of predictor names for future use in plots and results table.\n",
    "names = list(sfhomes_model.drop(['logTotal', 'AV_TOTAL'],axis =1))\n",
    "namesdf = sfhomes_model.drop(['logTotal', 'AV_TOTAL'],axis =1)\n",
    "\n",
    "# Convert Pandas dataframe into numpy arrays so we can use scikit-learn Random Forest and linear regression\n",
    "\n",
    "# Set numpy array for predictors\n",
    "x =np.asarray(sfhomes_model.drop(['logTotal', 'AV_TOTAL'],axis =1))\n",
    "# Set Target varialbe\n",
    "y = np.asarray(sfhomes_model['logTotal'])\n",
    "\n",
    "# Create training and validation dataset using 70/30 split.\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(x, y,test_size = 0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
